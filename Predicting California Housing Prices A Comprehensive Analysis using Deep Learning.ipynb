{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 1 with validation loss: 0.3972\n",
      "Epoch [1/61] - Training Loss: 0.5049, Validation Loss: 0.3972, R² (Accuracy): 69.69%\n",
      "Checkpoint saved at epoch 2 with validation loss: 0.3491\n",
      "Epoch [2/61] - Training Loss: 0.3928, Validation Loss: 0.3491, R² (Accuracy): 73.36%\n",
      "Checkpoint saved at epoch 3 with validation loss: 0.3345\n",
      "Epoch [3/61] - Training Loss: 0.3660, Validation Loss: 0.3345, R² (Accuracy): 74.47%\n",
      "Checkpoint saved at epoch 4 with validation loss: 0.3233\n",
      "Epoch [4/61] - Training Loss: 0.3535, Validation Loss: 0.3233, R² (Accuracy): 75.33%\n",
      "Checkpoint saved at epoch 5 with validation loss: 0.3226\n",
      "Epoch [5/61] - Training Loss: 0.3444, Validation Loss: 0.3226, R² (Accuracy): 75.38%\n",
      "Epoch [6/61] - Training Loss: 0.3380, Validation Loss: 0.3254, R² (Accuracy): 75.17%\n",
      "Checkpoint saved at epoch 7 with validation loss: 0.3062\n",
      "Epoch [7/61] - Training Loss: 0.3317, Validation Loss: 0.3062, R² (Accuracy): 76.63%\n",
      "Epoch [8/61] - Training Loss: 0.3251, Validation Loss: 0.3083, R² (Accuracy): 76.47%\n",
      "Checkpoint saved at epoch 9 with validation loss: 0.2940\n",
      "Epoch [9/61] - Training Loss: 0.3197, Validation Loss: 0.2940, R² (Accuracy): 77.56%\n",
      "Epoch [10/61] - Training Loss: 0.3096, Validation Loss: 0.2965, R² (Accuracy): 77.38%\n",
      "Epoch [11/61] - Training Loss: 0.3096, Validation Loss: 0.3002, R² (Accuracy): 77.09%\n",
      "Checkpoint saved at epoch 12 with validation loss: 0.2841\n",
      "Epoch [12/61] - Training Loss: 0.3031, Validation Loss: 0.2841, R² (Accuracy): 78.32%\n",
      "Epoch [13/61] - Training Loss: 0.3034, Validation Loss: 0.2919, R² (Accuracy): 77.73%\n",
      "Checkpoint saved at epoch 14 with validation loss: 0.2816\n",
      "Epoch [14/61] - Training Loss: 0.2936, Validation Loss: 0.2816, R² (Accuracy): 78.51%\n",
      "Epoch [15/61] - Training Loss: 0.2922, Validation Loss: 0.2889, R² (Accuracy): 77.95%\n",
      "Epoch [16/61] - Training Loss: 0.2863, Validation Loss: 0.2831, R² (Accuracy): 78.40%\n",
      "Checkpoint saved at epoch 17 with validation loss: 0.2781\n",
      "Epoch [17/61] - Training Loss: 0.2846, Validation Loss: 0.2781, R² (Accuracy): 78.78%\n",
      "Checkpoint saved at epoch 18 with validation loss: 0.2773\n",
      "Epoch [18/61] - Training Loss: 0.2819, Validation Loss: 0.2773, R² (Accuracy): 78.84%\n",
      "Epoch [19/61] - Training Loss: 0.2771, Validation Loss: 0.2782, R² (Accuracy): 78.77%\n",
      "Checkpoint saved at epoch 20 with validation loss: 0.2709\n",
      "Epoch [20/61] - Training Loss: 0.2754, Validation Loss: 0.2709, R² (Accuracy): 79.33%\n",
      "Epoch [21/61] - Training Loss: 0.2709, Validation Loss: 0.2796, R² (Accuracy): 78.66%\n",
      "Epoch [22/61] - Training Loss: 0.2688, Validation Loss: 0.2723, R² (Accuracy): 79.22%\n",
      "Checkpoint saved at epoch 23 with validation loss: 0.2668\n",
      "Epoch [23/61] - Training Loss: 0.2641, Validation Loss: 0.2668, R² (Accuracy): 79.64%\n",
      "Epoch [24/61] - Training Loss: 0.2577, Validation Loss: 0.2688, R² (Accuracy): 79.49%\n",
      "Epoch [25/61] - Training Loss: 0.2602, Validation Loss: 0.2708, R² (Accuracy): 79.33%\n",
      "Epoch [26/61] - Training Loss: 0.2555, Validation Loss: 0.2737, R² (Accuracy): 79.12%\n",
      "Checkpoint saved at epoch 27 with validation loss: 0.2588\n",
      "Epoch [27/61] - Training Loss: 0.2532, Validation Loss: 0.2588, R² (Accuracy): 80.25%\n",
      "Epoch [28/61] - Training Loss: 0.2495, Validation Loss: 0.2652, R² (Accuracy): 79.76%\n",
      "Epoch [29/61] - Training Loss: 0.2481, Validation Loss: 0.2664, R² (Accuracy): 79.67%\n",
      "Epoch [30/61] - Training Loss: 0.2455, Validation Loss: 0.2612, R² (Accuracy): 80.07%\n",
      "Checkpoint saved at epoch 31 with validation loss: 0.2560\n",
      "Epoch [31/61] - Training Loss: 0.2433, Validation Loss: 0.2560, R² (Accuracy): 80.46%\n",
      "Epoch [32/61] - Training Loss: 0.2436, Validation Loss: 0.2584, R² (Accuracy): 80.28%\n",
      "Epoch [33/61] - Training Loss: 0.2350, Validation Loss: 0.2591, R² (Accuracy): 80.23%\n",
      "Epoch [34/61] - Training Loss: 0.2346, Validation Loss: 0.2573, R² (Accuracy): 80.36%\n",
      "Epoch [35/61] - Training Loss: 0.2327, Validation Loss: 0.2570, R² (Accuracy): 80.39%\n",
      "Epoch [36/61] - Training Loss: 0.2301, Validation Loss: 0.2587, R² (Accuracy): 80.26%\n",
      "Checkpoint saved at epoch 37 with validation loss: 0.2534\n",
      "Epoch [37/61] - Training Loss: 0.2303, Validation Loss: 0.2534, R² (Accuracy): 80.66%\n",
      "Epoch [38/61] - Training Loss: 0.2265, Validation Loss: 0.2540, R² (Accuracy): 80.62%\n",
      "Epoch [39/61] - Training Loss: 0.2236, Validation Loss: 0.2568, R² (Accuracy): 80.40%\n",
      "Epoch [40/61] - Training Loss: 0.2222, Validation Loss: 0.2539, R² (Accuracy): 80.63%\n",
      "Epoch [41/61] - Training Loss: 0.2223, Validation Loss: 0.2555, R² (Accuracy): 80.50%\n",
      "Checkpoint saved at epoch 42 with validation loss: 0.2530\n",
      "Epoch [42/61] - Training Loss: 0.2174, Validation Loss: 0.2530, R² (Accuracy): 80.69%\n",
      "Epoch [43/61] - Training Loss: 0.2198, Validation Loss: 0.2541, R² (Accuracy): 80.61%\n",
      "Epoch [44/61] - Training Loss: 0.2150, Validation Loss: 0.2540, R² (Accuracy): 80.62%\n",
      "Epoch [45/61] - Training Loss: 0.2148, Validation Loss: 0.2543, R² (Accuracy): 80.60%\n",
      "Epoch [46/61] - Training Loss: 0.2167, Validation Loss: 0.2535, R² (Accuracy): 80.65%\n",
      "Epoch [47/61] - Training Loss: 0.2130, Validation Loss: 0.2543, R² (Accuracy): 80.60%\n",
      "Epoch [48/61] - Training Loss: 0.2132, Validation Loss: 0.2537, R² (Accuracy): 80.64%\n",
      "Epoch [49/61] - Training Loss: 0.2148, Validation Loss: 0.2538, R² (Accuracy): 80.63%\n",
      "Epoch [50/61] - Training Loss: 0.2165, Validation Loss: 0.2538, R² (Accuracy): 80.63%\n",
      "Epoch [51/61] - Training Loss: 0.2135, Validation Loss: 0.2538, R² (Accuracy): 80.63%\n",
      "Epoch [52/61] - Training Loss: 0.2113, Validation Loss: 0.2538, R² (Accuracy): 80.63%\n",
      "Epoch [53/61] - Training Loss: 0.2134, Validation Loss: 0.2537, R² (Accuracy): 80.64%\n",
      "Epoch [54/61] - Training Loss: 0.2129, Validation Loss: 0.2540, R² (Accuracy): 80.62%\n",
      "Epoch [55/61] - Training Loss: 0.2110, Validation Loss: 0.2540, R² (Accuracy): 80.62%\n",
      "Epoch [56/61] - Training Loss: 0.2135, Validation Loss: 0.2537, R² (Accuracy): 80.64%\n",
      "Epoch [57/61] - Training Loss: 0.2162, Validation Loss: 0.2541, R² (Accuracy): 80.61%\n",
      "Epoch [58/61] - Training Loss: 0.2146, Validation Loss: 0.2536, R² (Accuracy): 80.65%\n",
      "Epoch [59/61] - Training Loss: 0.2159, Validation Loss: 0.2538, R² (Accuracy): 80.63%\n",
      "Epoch [60/61] - Training Loss: 0.2151, Validation Loss: 0.2536, R² (Accuracy): 80.65%\n",
      "Checkpoint saved at epoch 61 with validation loss: 0.2528\n",
      "Epoch [61/61] - Training Loss: 0.2161, Validation Loss: 0.2528, R² (Accuracy): 80.71%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Fetch dataset and split\n",
    "dataset = fetch_california_housing()\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Polynomial Features for feature engineering (with interaction terms only)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_val_poly = poly.transform(x_val)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train_poly = scaler.fit_transform(x_train_poly)\n",
    "x_val_poly = scaler.transform(x_val_poly)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train_poly, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "x_val_tensor = torch.tensor(x_val_poly, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Create DataLoaders for mini-batch training\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the improved model with LayerNorm and adjusted dropout rates\n",
    "class ImprovedRegressionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedRegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_train_poly.shape[1], 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.ln2 = nn.LayerNorm(256)\n",
    "        self.dropout2 = nn.Dropout(0.15)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.ln3 = nn.LayerNorm(128)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.ln4 = nn.LayerNorm(64)\n",
    "        self.dropout4 = nn.Dropout(0.05)\n",
    "\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.ln1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.ln2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.ln3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.ln4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate model, loss function, and optimizer (AdamW for better weight decay handling)\n",
    "model = ImprovedRegressionNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "# Use CosineAnnealingLR as a learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# Create a directory for checkpoints and set the path\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Function to save a checkpoint\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# Function to calculate R-squared\n",
    "def r2_score_torch(y_true, y_pred):\n",
    "    y_true_np = y_true.cpu().detach().numpy()\n",
    "    y_pred_np = y_pred.cpu().detach().numpy()\n",
    "    return r2_score(y_true_np, y_pred_np)\n",
    "\n",
    "# Training and validation loop with checkpointing\n",
    "num_epochs = 61 # Increased number of epochs\n",
    "patience = 30  # Adjusted patience for early stopping\n",
    "no_improvement_count = 0\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training step\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        pred_train = model(x_batch)\n",
    "        loss = criterion(pred_train, y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping with increased norm\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            pred_val = model(x_batch)\n",
    "            loss = criterion(pred_val, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Calculate R-squared as \"accuracy\"\n",
    "    val_r2 = r2_score_torch(y_val_tensor, model(x_val_tensor))\n",
    "    val_accuracy_percent = val_r2 * 100  # Convert to percentage\n",
    "\n",
    "    # Check if validation loss improved and save checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(model, optimizer, epoch, train_loss, val_loss)\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    # Early stopping if no improvement\n",
    "    if no_improvement_count >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    # Log progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, R² (Accuracy): {val_accuracy_percent:.2f}%\")\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "    writer.add_scalar('R²/validation', val_accuracy_percent, epoch)\n",
    "\n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Tkinter GUI for prediction\n",
    "def predict_price():\n",
    "    # Attempt to get input values from the GUI\n",
    "    try:\n",
    "        # Get input values\n",
    "        features = [float(entry.get()) for entry in feature_entries]\n",
    "        \n",
    "        # Ensure we have exactly 8 features\n",
    "        if len(features) != len(feature_names):\n",
    "            raise ValueError(\"Please enter all features.\")\n",
    "\n",
    "        # Transform features with polynomial features\n",
    "        features_poly = poly.transform([features])\n",
    "\n",
    "        # Scale the features\n",
    "        features_poly_scaled = scaler.transform(features_poly)\n",
    "\n",
    "        # Convert to tensor\n",
    "        features_tensor = torch.tensor(features_poly_scaled, dtype=torch.float32)\n",
    "\n",
    "        # Predict housing price\n",
    "        with torch.no_grad():\n",
    "            price = model(features_tensor).item()\n",
    "        \n",
    "        # Display the result\n",
    "        messagebox.showinfo(\"Predicted Price\", f\"Predicted Housing Price: ${price:.2f}\")\n",
    "\n",
    "    except ValueError as ve:\n",
    "        messagebox.showerror(\"Input Error\", str(ve))\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", \"An error occurred during prediction.\")\n",
    "\n",
    "# Create a Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"California Housing Price Predictor\")\n",
    "window.configure(bg='darkgray')  # Set background color\n",
    "\n",
    "# Feature names for user input\n",
    "feature_names = dataset.feature_names\n",
    "feature_entries = []\n",
    "\n",
    "# Create a frame to center the elements\n",
    "frame = tk.Frame(window, bg='darkgray')\n",
    "frame.pack(pady=20)\n",
    "\n",
    "# Create entry fields for each feature\n",
    "for feature in feature_names:\n",
    "    label = tk.Label(frame, text=feature, bg='darkgray', fg='white')  # White text on dark gray background\n",
    "    label.pack(pady=5)  # Add padding for better spacing\n",
    "    entry = tk.Entry(frame, width=30)  # Increase the width of the entry field\n",
    "    entry.pack(pady=5)  # Add padding for better spacing\n",
    "    feature_entries.append(entry)\n",
    "\n",
    "# Create a button to trigger prediction\n",
    "predict_button = tk.Button(frame, text=\"Predict Price\", command=predict_price)\n",
    "predict_button.pack(pady=10)  # Add padding for better spacing\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
